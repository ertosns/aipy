<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>aipy: aipy.aipy.utils Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">aipy
   &#160;<span id="projectnumber">0.1</span>
   </div>
   <div id="projectbrief">MachineLearninglibraryforeducationalpurposes</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>aipy</b></li><li class="navelem"><b>aipy</b></li><li class="navelem"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html">utils</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">aipy.aipy.utils Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:adc552a252a7228b685a589a2778c9229"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#adc552a252a7228b685a589a2778c9229">initialize_with_zeros</a> (dim)</td></tr>
<tr class="memdesc:adc552a252a7228b685a589a2778c9229"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.  <a href="namespaceaipy_1_1aipy_1_1utils.html#adc552a252a7228b685a589a2778c9229">More...</a><br /></td></tr>
<tr class="separator:adc552a252a7228b685a589a2778c9229"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa064d8aa342cee14bd78510b0e607860"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#aa064d8aa342cee14bd78510b0e607860">linear</a> (w, X, b)</td></tr>
<tr class="memdesc:aa064d8aa342cee14bd78510b0e607860"><td class="mdescLeft">&#160;</td><td class="mdescRight">linear activation function  <a href="namespaceaipy_1_1aipy_1_1utils.html#aa064d8aa342cee14bd78510b0e607860">More...</a><br /></td></tr>
<tr class="separator:aa064d8aa342cee14bd78510b0e607860"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab953b6a76b3d91de0f6b42d9d6d8b58b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ab953b6a76b3d91de0f6b42d9d6d8b58b">sigmoid</a> (z)</td></tr>
<tr class="memdesc:ab953b6a76b3d91de0f6b42d9d6d8b58b"><td class="mdescLeft">&#160;</td><td class="mdescRight">sigmoid activation  <a href="namespaceaipy_1_1aipy_1_1utils.html#ab953b6a76b3d91de0f6b42d9d6d8b58b">More...</a><br /></td></tr>
<tr class="separator:ab953b6a76b3d91de0f6b42d9d6d8b58b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21734b28fb87a0c8494e865442d9b4ec"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a21734b28fb87a0c8494e865442d9b4ec">deep_sigmoid</a> (Z)</td></tr>
<tr class="memdesc:a21734b28fb87a0c8494e865442d9b4ec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements the sigmoid activation in numpy.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a21734b28fb87a0c8494e865442d9b4ec">More...</a><br /></td></tr>
<tr class="separator:a21734b28fb87a0c8494e865442d9b4ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a069feeb21ef242f65007f62e77509639"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a069feeb21ef242f65007f62e77509639">compute_cost</a> (Y, h)</td></tr>
<tr class="memdesc:a069feeb21ef242f65007f62e77509639"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute log likelihood of the logistic regression  <a href="namespaceaipy_1_1aipy_1_1utils.html#a069feeb21ef242f65007f62e77509639">More...</a><br /></td></tr>
<tr class="separator:a069feeb21ef242f65007f62e77509639"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1d2386f78b74fda92f3eedb0690688d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ac1d2386f78b74fda92f3eedb0690688d">deep_compute_cost</a> (AL, Y)</td></tr>
<tr class="memdesc:ac1d2386f78b74fda92f3eedb0690688d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the cost function defined by equation (7).  <a href="namespaceaipy_1_1aipy_1_1utils.html#ac1d2386f78b74fda92f3eedb0690688d">More...</a><br /></td></tr>
<tr class="separator:ac1d2386f78b74fda92f3eedb0690688d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87e9e817af292c366226f644168454a7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a87e9e817af292c366226f644168454a7">derive_weight</a> (X, Y, h)</td></tr>
<tr class="memdesc:a87e9e817af292c366226f644168454a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">compute dJ/dw, and dJ/db for logistic regression  <a href="namespaceaipy_1_1aipy_1_1utils.html#a87e9e817af292c366226f644168454a7">More...</a><br /></td></tr>
<tr class="separator:a87e9e817af292c366226f644168454a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a757ce3a23c10fbc489f586d772381d68"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a757ce3a23c10fbc489f586d772381d68">update_weight</a> (w, dw, b, db, alpha)</td></tr>
<tr class="memdesc:a757ce3a23c10fbc489f586d772381d68"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update weight values with single gradient descent step.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a757ce3a23c10fbc489f586d772381d68">More...</a><br /></td></tr>
<tr class="separator:a757ce3a23c10fbc489f586d772381d68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4b8d65cdcdd5476f1fd2c871464c391"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#af4b8d65cdcdd5476f1fd2c871464c391">update_parameters</a> (parameters, grads, learning_rate)</td></tr>
<tr class="memdesc:af4b8d65cdcdd5476f1fd2c871464c391"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update parameters using gradient descent.  <a href="namespaceaipy_1_1aipy_1_1utils.html#af4b8d65cdcdd5476f1fd2c871464c391">More...</a><br /></td></tr>
<tr class="separator:af4b8d65cdcdd5476f1fd2c871464c391"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58e2fccbc2a5b25f8f30607629ed38ae"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a58e2fccbc2a5b25f8f30607629ed38ae">propagate</a> (w, b, X, Y)</td></tr>
<tr class="memdesc:a58e2fccbc2a5b25f8f30607629ed38ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement Forward, and Backward propagation, the cost function and its gradient .  <a href="namespaceaipy_1_1aipy_1_1utils.html#a58e2fccbc2a5b25f8f30607629ed38ae">More...</a><br /></td></tr>
<tr class="separator:a58e2fccbc2a5b25f8f30607629ed38ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96dbd24dcc5f813264a1bc91be208946"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a96dbd24dcc5f813264a1bc91be208946">gradient_descent</a> (w, b, X, Y, num_iterations=1000, alpha=0.001, print_cost=False)</td></tr>
<tr class="memdesc:a96dbd24dcc5f813264a1bc91be208946"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function optimizes w and b by running a gradient descent algorithm.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a96dbd24dcc5f813264a1bc91be208946">More...</a><br /></td></tr>
<tr class="separator:a96dbd24dcc5f813264a1bc91be208946"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88d9dbe6880b5c7ce1978a290b21b0db"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a88d9dbe6880b5c7ce1978a290b21b0db">predict</a> (w, b, X)</td></tr>
<tr class="memdesc:a88d9dbe6880b5c7ce1978a290b21b0db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)  <a href="namespaceaipy_1_1aipy_1_1utils.html#a88d9dbe6880b5c7ce1978a290b21b0db">More...</a><br /></td></tr>
<tr class="separator:a88d9dbe6880b5c7ce1978a290b21b0db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a314bb57a2c296337ea2f273c46f4e7e7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a314bb57a2c296337ea2f273c46f4e7e7">relu</a> (Z)</td></tr>
<tr class="memdesc:a314bb57a2c296337ea2f273c46f4e7e7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the RELU function.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a314bb57a2c296337ea2f273c46f4e7e7">More...</a><br /></td></tr>
<tr class="separator:a314bb57a2c296337ea2f273c46f4e7e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae93689ee55421e957e55192016219da0"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ae93689ee55421e957e55192016219da0">relu_backward</a> (dA, cache)</td></tr>
<tr class="memdesc:ae93689ee55421e957e55192016219da0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the backward propagation for a single RELU unit.  <a href="namespaceaipy_1_1aipy_1_1utils.html#ae93689ee55421e957e55192016219da0">More...</a><br /></td></tr>
<tr class="separator:ae93689ee55421e957e55192016219da0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec2b9988afa351577eb52f731029fc89"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#aec2b9988afa351577eb52f731029fc89">sigmoid_backward</a> (dA, cache)</td></tr>
<tr class="memdesc:aec2b9988afa351577eb52f731029fc89"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the backward propagation for a single SIGMOID unit.  <a href="namespaceaipy_1_1aipy_1_1utils.html#aec2b9988afa351577eb52f731029fc89">More...</a><br /></td></tr>
<tr class="separator:aec2b9988afa351577eb52f731029fc89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5ddc42640b585e150188f5afba6dfe7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ac5ddc42640b585e150188f5afba6dfe7">initialize_parameters</a> (n_x, n_h, n_y)</td></tr>
<tr class="memdesc:ac5ddc42640b585e150188f5afba6dfe7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Randomly initialize the parameters W, b.  <a href="namespaceaipy_1_1aipy_1_1utils.html#ac5ddc42640b585e150188f5afba6dfe7">More...</a><br /></td></tr>
<tr class="separator:ac5ddc42640b585e150188f5afba6dfe7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbac86750318632038fd04f8ad723177"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#afbac86750318632038fd04f8ad723177">linear_forward</a> (A, W, b)</td></tr>
<tr class="memdesc:afbac86750318632038fd04f8ad723177"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the linear part of a layer's forward propagation.  <a href="namespaceaipy_1_1aipy_1_1utils.html#afbac86750318632038fd04f8ad723177">More...</a><br /></td></tr>
<tr class="separator:afbac86750318632038fd04f8ad723177"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a08062c4331864f05b91e3e6c385996a5"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a08062c4331864f05b91e3e6c385996a5">forward_propagation</a> (X, parameters)</td></tr>
<tr class="memdesc:a08062c4331864f05b91e3e6c385996a5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement Forward propagation.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a08062c4331864f05b91e3e6c385996a5">More...</a><br /></td></tr>
<tr class="separator:a08062c4331864f05b91e3e6c385996a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac22409ca5bf4e2a84069b8832259aa2a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ac22409ca5bf4e2a84069b8832259aa2a">deep_initialization</a> (layer_dims)</td></tr>
<tr class="memdesc:ac22409ca5bf4e2a84069b8832259aa2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">deep neural networks #  <a href="namespaceaipy_1_1aipy_1_1utils.html#ac22409ca5bf4e2a84069b8832259aa2a">More...</a><br /></td></tr>
<tr class="separator:ac22409ca5bf4e2a84069b8832259aa2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd0b296a51a42b8841de2e0ec584e21c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#abd0b296a51a42b8841de2e0ec584e21c">deep_linear</a> (W, A, b)</td></tr>
<tr class="memdesc:abd0b296a51a42b8841de2e0ec584e21c"><td class="mdescLeft">&#160;</td><td class="mdescRight">linear activation function  <a href="namespaceaipy_1_1aipy_1_1utils.html#abd0b296a51a42b8841de2e0ec584e21c">More...</a><br /></td></tr>
<tr class="separator:abd0b296a51a42b8841de2e0ec584e21c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae772d750fa98fd997ee0f20e2e255f72"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#ae772d750fa98fd997ee0f20e2e255f72">deep_activation</a> (z)</td></tr>
<tr class="memdesc:ae772d750fa98fd997ee0f20e2e255f72"><td class="mdescLeft">&#160;</td><td class="mdescRight">Tan activation function.  <a href="namespaceaipy_1_1aipy_1_1utils.html#ae772d750fa98fd997ee0f20e2e255f72">More...</a><br /></td></tr>
<tr class="separator:ae772d750fa98fd997ee0f20e2e255f72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9053ccc44ee85c2b505ca8235b264ba4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a9053ccc44ee85c2b505ca8235b264ba4">deep_linear_activation_forward</a> (A_prev, W, b, activation)</td></tr>
<tr class="memdesc:a9053ccc44ee85c2b505ca8235b264ba4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a9053ccc44ee85c2b505ca8235b264ba4">More...</a><br /></td></tr>
<tr class="separator:a9053ccc44ee85c2b505ca8235b264ba4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57e2d187ebc733e018a0dcf6a506af9a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceaipy_1_1aipy_1_1utils.html#a57e2d187ebc733e018a0dcf6a506af9a">deep_linear_activation_backward</a> (dA, cache, activation)</td></tr>
<tr class="memdesc:a57e2d187ebc733e018a0dcf6a506af9a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer.  <a href="namespaceaipy_1_1aipy_1_1utils.html#a57e2d187ebc733e018a0dcf6a506af9a">More...</a><br /></td></tr>
<tr class="separator:a57e2d187ebc733e018a0dcf6a506af9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">@package aipy

this is utility file for aipy library
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a069feeb21ef242f65007f62e77509639"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a069feeb21ef242f65007f62e77509639">&#9670;&nbsp;</a></span>compute_cost()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.compute_cost </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>compute log likelihood of the logistic regression </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">Y</td><td>(1,m) labeled vector Output </td></tr>
    <tr><td class="paramname">h</td><td>(1,m) estimated output </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>J (1) scalar cost function output </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00051">51</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="keyword">def </span>compute_cost(Y, h):</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    m=Y.shape[1]</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    <span class="keyword">def </span>compute_loss():</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        L=np.dot(Y.T, np.log(h)) + np.dot((1-Y).T, np.log((1-h)))</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;        <span class="keywordflow">return</span> L.squeeze()</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    J = -1.0/m * compute_loss()</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    <span class="keywordflow">return</span> J</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160; </div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae772d750fa98fd997ee0f20e2e255f72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae772d750fa98fd997ee0f20e2e255f72">&#9670;&nbsp;</a></span>deep_activation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_activation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>z</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Tan activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">z</td><td>is the linear activation </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>tan(z) </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00332">332</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="keyword">def </span>deep_activation(z):</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;    <span class="keywordflow">return</span> np.tanh(z)</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac1d2386f78b74fda92f3eedb0690688d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1d2386f78b74fda92f3eedb0690688d">&#9670;&nbsp;</a></span>deep_compute_cost()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_compute_cost </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>AL</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the cost function defined by equation (7). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">AL</td><td>probability vector corresponding to your label predictions, shape (1, number of examples) </td></tr>
    <tr><td class="paramname">Y</td><td>true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cost cross-entropy cost </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00065">65</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="keyword">def </span>deep_compute_cost(AL, Y):</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    m = Y.shape[1]</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="comment"># Compute loss from aL and y.</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    cost = -1.0/m * np.sum(np.multiply(Y, np.log(AL)) + \</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;                           np.multiply((1-Y), np.log(1-AL)))</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="comment"># To make sure your cost&#39;s shape is what we expect</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="comment"># (e.g. this turns [[17]] into 17).</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    cost = cost.squeeze()</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;    assert(cost.shape == ())</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    </div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    <span class="keywordflow">return</span> cost</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac22409ca5bf4e2a84069b8832259aa2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac22409ca5bf4e2a84069b8832259aa2a">&#9670;&nbsp;</a></span>deep_initialization()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_initialization </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layer_dims</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>deep neural networks # </p>
<p>Randomly initialize weight, and bias parameters of given layer dimensions.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer_dims</td><td>python array (list) containing the dimensions of each layer in our network </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>parameters python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": Wl weight matrix of shape(layer_dims[l], layer_dims[l-1]) bl bias vector of shape (layer_dims[l], 1) </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00307">307</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="keyword">def </span>deep_initialization(layer_dims):</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    np.random.seed(3)</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    parameters = {}</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;    L = len(layer_dims)</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    <span class="keywordflow">for</span> l <span class="keywordflow">in</span> range(1, L):</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        parameters[<span class="stringliteral">&#39;W&#39;</span> + str(l)] = \</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;            np.random.randn(layer_dims[l], layer_dims[l-1])*0.01</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;        parameters[<span class="stringliteral">&#39;b&#39;</span> + str(l)] = \</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;            np.zeros((layer_dims[l], 1))*0.01</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    <span class="keywordflow">return</span> parameters</div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="abd0b296a51a42b8841de2e0ec584e21c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd0b296a51a42b8841de2e0ec584e21c">&#9670;&nbsp;</a></span>deep_linear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_linear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>linear activation function </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">W</td><td>(n_i,n_{i-1}) weight matrix </td></tr>
    <tr><td class="paramname">A</td><td>(n_{i-1}, m) input matrix </td></tr>
    <tr><td class="paramname">b</td><td>(1) bias </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>z (1,m) linear estimation </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00324">324</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="keyword">def </span>deep_linear(W, A, b):</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;    z = np.dot(W, A) + b</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;    <span class="keywordflow">return</span> z</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a57e2d187ebc733e018a0dcf6a506af9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a57e2d187ebc733e018a0dcf6a506af9a">&#9670;&nbsp;</a></span>deep_linear_activation_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_linear_activation_backward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cache</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dA</td><td>post-activation gradient for current layer l </td></tr>
    <tr><td class="paramname">cache</td><td>tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently </td></tr>
    <tr><td class="paramname">activation</td><td>the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>dA_prev Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev. </dd>
<dd>
dW Gradient of the cost with respect to W (current layer l), same shape as W. </dd>
<dd>
db Gradient of the cost with respect to b (current layer l), same shape as b. </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00366">366</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="keyword">def </span>deep_linear_activation_backward(dA, cache, activation):</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    </div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;    <span class="keyword">def </span>deep_linear_backward(dZ, cache):</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;        A_prev, W, b = cache</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;        m = A_prev.shape[1]</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160; </div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;        dW = 1.0/m *np.dot(dZ, A_prev.T)</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        db = 1.0/m * np.sum(dZ, axis=1, keepdims=<span class="keyword">True</span>)</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        dA_prev = np.dot(W.T, dZ)</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;    </div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;        <span class="keyword">assert</span> (dA_prev.shape == A_prev.shape)</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;        <span class="keyword">assert</span> (dW.shape == W.shape)</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;        <span class="keyword">assert</span> (db.shape == b.shape)</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        </div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;        <span class="keywordflow">return</span> dA_prev, dW, db</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160; </div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;    linear_cache, activation_cache = cache</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    <span class="keywordflow">if</span> activation == <span class="stringliteral">&quot;relu&quot;</span>:</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;        dZ = relu_backward(dA, activation_cache)</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        dA_prev, dW, db = deep_linear_backward(dZ, linear_cache)</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    <span class="keywordflow">elif</span> activation == <span class="stringliteral">&quot;sigmoid&quot;</span>:</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;        dZ = sigmoid_backward(dA, activation_cache)</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;        dA_prev, dW, db = deep_linear_backward(dZ, linear_cache)</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;    <span class="keywordflow">return</span> dA_prev, dW, db</div>
</div><!-- fragment -->
</div>
</div>
<a id="a9053ccc44ee85c2b505ca8235b264ba4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9053ccc44ee85c2b505ca8235b264ba4">&#9670;&nbsp;</a></span>deep_linear_activation_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_linear_activation_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A_prev</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>activation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A_prev</td><td>activations from previous layer (or input data): (size of previous layer, number of examples) </td></tr>
    <tr><td class="paramname">W</td><td>weights matrix: numpy array of shape (size of current layer, size of previous layer) </td></tr>
    <tr><td class="paramname">b</td><td>bias vector, numpy array of shape (size of the current layer, 1) </td></tr>
    <tr><td class="paramname">activation</td><td>the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A the output of the activation function, also called the post-activation value </dd>
<dd>
cache a python tuple containing "linear_cache" and "activation_cache", stored for computing the backward pass efficiently </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00343">343</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="keyword">def </span>deep_linear_activation_forward(A_prev, W, b, activation):</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;    <span class="keywordflow">if</span> activation == <span class="stringliteral">&quot;sigmoid&quot;</span>:</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        Z, linear_cache = linear_forward(A_prev, W, b)</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        <span class="comment"># TODO implement cached sigmoid</span></div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        A, activation_cache = deep_sigmoid(Z)</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;    </div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;    <span class="keywordflow">elif</span> activation == <span class="stringliteral">&quot;relu&quot;</span>:</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;        Z, linear_cache = linear_forward(A_prev, W, b)<span class="comment">#</span></div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;        <span class="comment">#TODO implemnet cached relu</span></div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;        A, activation_cache = relu(Z)</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;    </div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;    <span class="keyword">assert</span> (A.shape == (W.shape[0], A_prev.shape[1]))</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    cache = (linear_cache, activation_cache)</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;    <span class="keywordflow">return</span> A, cache</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a21734b28fb87a0c8494e865442d9b4ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a21734b28fb87a0c8494e865442d9b4ec">&#9670;&nbsp;</a></span>deep_sigmoid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.deep_sigmoid </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implements the sigmoid activation in numpy. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">Z</td><td>numpy array of any shape </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A output of sigmoid(z), same shape as Z </dd>
<dd>
cache returns Z as well, useful during backpropagation </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00041">41</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="keyword">def </span>deep_sigmoid(Z):</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    A = 1/(1+np.exp(-Z))</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;    cache = Z</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    <span class="keywordflow">return</span> A, cache</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a87e9e817af292c366226f644168454a7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87e9e817af292c366226f644168454a7">&#9670;&nbsp;</a></span>derive_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.derive_weight </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>h</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>compute dJ/dw, and dJ/db for logistic regression </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>(n,m) input matrix </td></tr>
    <tr><td class="paramname">Y</td><td>(1,m) output vector </td></tr>
    <tr><td class="paramname">h</td><td>(1,m) activation vector </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>dw (n,1) vector derivate of cost function w.r.t w </dd>
<dd>
db (1) scalar derivate of cost function w.r.t b </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00084">84</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="keyword">def </span>derive_weight(X, Y, h):    </div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;    m=len(X[0])</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    dw = 1.0/m * (np.dot(X, (h-Y).T))</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    db = 1.0/m * np.sum(h-Y)</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;    <span class="keywordflow">return</span> dw, db</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a08062c4331864f05b91e3e6c385996a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a08062c4331864f05b91e3e6c385996a5">&#9670;&nbsp;</a></span>forward_propagation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.forward_propagation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parameters</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement Forward propagation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>input data of size (n_x, m) </td></tr>
    <tr><td class="paramname">parameters</td><td>initialization return value </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A2 The sigmoid output of the second activation </dd>
<dd>
cache a dictionary containing "Z1", "A1", "Z2" and "A2" </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00276">276</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;<span class="keyword">def </span>forward_propagation(X, parameters):</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;    W1 = parameters[<span class="stringliteral">&#39;W1&#39;</span>]</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    b1 = parameters[<span class="stringliteral">&#39;b1&#39;</span>]</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    W2 = parameters[<span class="stringliteral">&#39;W2&#39;</span>]</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;    b2 = parameters[<span class="stringliteral">&#39;b2&#39;</span>]</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;    </div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;    Z1 = deep_linear(W1, X, b1)</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;    A1 = deep_activation(Z1)</div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;    Z2 = deep_linear(W2, A1, b2)</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    A2 = sigmoid(Z2)</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    </div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    assert(A2.shape == (1, X.shape[1]))</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160; </div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;    cache = {<span class="stringliteral">&quot;Z1&quot;</span>: Z1,</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;             <span class="stringliteral">&quot;A1&quot;</span>: A1,</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;             <span class="stringliteral">&quot;Z2&quot;</span>: Z2,</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;             <span class="stringliteral">&quot;A2&quot;</span>: A2}</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;    <span class="keywordflow">return</span> A2, cache</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160; </div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a96dbd24dcc5f813264a1bc91be208946"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96dbd24dcc5f813264a1bc91be208946">&#9670;&nbsp;</a></span>gradient_descent()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.gradient_descent </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_iterations</em> = <code>1000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em> = <code>0.001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>print_cost</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function optimizes w and b by running a gradient descent algorithm. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>weights, a numpy array of size (n,1) </td></tr>
    <tr><td class="paramname">b</td><td>bias, a scalar </td></tr>
    <tr><td class="paramname">X</td><td>data of shape (n,m) </td></tr>
    <tr><td class="paramname">Y</td><td>true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) </td></tr>
    <tr><td class="paramname">num_iterations</td><td>number of iterations of the optimization loop </td></tr>
    <tr><td class="paramname">learning_rate</td><td>learning rate of the gradient descent update rule </td></tr>
    <tr><td class="paramname">print_cost</td><td>True to print the loss every 100 steps </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>params dictionary containing the weights w and bias b </dd>
<dd>
grads dictionary containing the gradients of the weights and bias with respect to the cost function </dd>
<dd>
costs list of all the costs computed during the optimization, this will be used to plot the learning curve. </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00154">154</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="keyword">def </span>gradient_descent(w, b, X, Y, num_iterations=1000, alpha=0.001, print_cost = False):</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    costs = []</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(num_iterations):</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        grads, cost = propagate(w, b, X, Y)</div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;        dw = grads[<span class="stringliteral">&quot;dw&quot;</span>]</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;        db = grads[<span class="stringliteral">&quot;db&quot;</span>]</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        w,b = update_weight(w, dw, b, db, alpha)</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        <span class="comment"># track cost</span></div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        <span class="keywordflow">if</span> i % 100 == 0:</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;            costs.append(cost)</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;        <span class="comment"># Print the cost every 100 training iterations</span></div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        <span class="keywordflow">if</span> print_cost <span class="keywordflow">and</span> i % 100 == 0:</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;            <span class="keywordflow">print</span> (<span class="stringliteral">&quot;Cost after iteration %i: %f&quot;</span> %(i, cost))</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    </div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    params = {<span class="stringliteral">&quot;w&quot;</span>: w,</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;              <span class="stringliteral">&quot;b&quot;</span>: b}</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;    </div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;    grads = {<span class="stringliteral">&quot;dw&quot;</span>: dw,</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;             <span class="stringliteral">&quot;db&quot;</span>: db}</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    </div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;    <span class="keywordflow">return</span> params, grads, costs</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac5ddc42640b585e150188f5afba6dfe7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5ddc42640b585e150188f5afba6dfe7">&#9670;&nbsp;</a></span>initialize_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.initialize_parameters </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_h</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n_y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Randomly initialize the parameters W, b. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n_x</td><td>size of the input layer </td></tr>
    <tr><td class="paramname">n_h</td><td>size of the hidden layer </td></tr>
    <tr><td class="paramname">n_y</td><td>size of the output layer </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>params python dictionary containing your parameters: W1 &ndash; weight matrix of shape (n_h, n_x) b1 &ndash; bias vector of shape (n_h, 1) W2 &ndash; weight matrix of shape (n_y, n_h) b2 &ndash; bias vector of shape (n_y, 1) </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00242">242</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="keyword">def </span>initialize_parameters(n_x, n_h, n_y):</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;    np.random.seed(2) </div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;    W1 = np.random.random((n_h, n_x))*0.01</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    b1 = np.zeros((n_h, 1))*0.01</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    W2 = np.random.randn(n_y, n_h)*0.01</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;    b2 = np.zeros((n_y, 1))*0.01    </div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;    <span class="keyword">assert</span> (W1.shape == (n_h, n_x))</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;    <span class="keyword">assert</span> (b1.shape == (n_h, 1))</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;    <span class="keyword">assert</span> (W2.shape == (n_y, n_h))</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    <span class="keyword">assert</span> (b2.shape == (n_y, 1))</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    parameters = {<span class="stringliteral">&quot;W1&quot;</span>: W1,</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;                  <span class="stringliteral">&quot;b1&quot;</span>: b1,</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;                  <span class="stringliteral">&quot;W2&quot;</span>: W2,</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;                  <span class="stringliteral">&quot;b2&quot;</span>: b2}</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;    <span class="keywordflow">return</span> parameters</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="adc552a252a7228b685a589a2778c9229"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc552a252a7228b685a589a2778c9229">&#9670;&nbsp;</a></span>initialize_with_zeros()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.initialize_with_zeros </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dim</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dim</td><td>size of the w vector we want (or number of parameters in this case) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>w initialized vector of shape (dim, 1) </dd>
<dd>
b initialized scalar (corresponds to the bias) </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00013">13</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="keyword">def </span>initialize_with_zeros(dim):</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;    w = np.zeros((dim, 1))</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    b = 0</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;    <span class="keywordflow">return</span> w, b</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa064d8aa342cee14bd78510b0e607860"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa064d8aa342cee14bd78510b0e607860">&#9670;&nbsp;</a></span>linear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.linear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>linear activation function </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>(m,1) weight matrix </td></tr>
    <tr><td class="paramname">X</td><td>(m,n) input matrix </td></tr>
    <tr><td class="paramname">b</td><td>(1) bias </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>z (1,m) linear estimation </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00024">24</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="keyword">def </span>linear(w, X, b):</div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;    z = np.dot(w.T, X) + b</div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;    <span class="keywordflow">return</span> z</div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160; </div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="afbac86750318632038fd04f8ad723177"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afbac86750318632038fd04f8ad723177">&#9670;&nbsp;</a></span>linear_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.linear_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>W</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the linear part of a layer's forward propagation. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>activations from previous layer (or input data): (size of previous layer, number of examples) </td></tr>
    <tr><td class="paramname">W</td><td>weights matrix: numpy array of shape (size of current layer, size of previous layer) </td></tr>
    <tr><td class="paramname">b</td><td>bias vector, numpy array of shape (size of the current layer, 1) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Z the input of the activation function, also called pre-activation parameter </dd>
<dd>
cache a python tuple containing "A", "W" and "b" ; stored for computing the backward pass efficiently </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00265">265</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="keyword">def </span>linear_forward(A, W, b):</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;    Z = deep_linear(W, A, b)    </div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;    cache = (A, W, b)</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;    <span class="keywordflow">return</span> Z, cache</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a88d9dbe6880b5c7ce1978a290b21b0db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88d9dbe6880b5c7ce1978a290b21b0db">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>weights, a numpy array of size (n, 1) </td></tr>
    <tr><td class="paramname">b</td><td>bias, a scalar </td></tr>
    <tr><td class="paramname">X</td><td>data of size (n,m) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Y_prediction a numpy array (vector) containing all predictions (0/1) for the examples in X </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00182">182</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="keyword">def </span>predict(w, b, X):</div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;    m = X.shape[1]</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;    Y_prediction = np.zeros((1,m))</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;    w = w.reshape(X.shape[0], 1)</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;    Z = linear(w, X, b)</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    A = sigmoid(Z)</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    <span class="comment">#TODO replace this with pandas apply function</span></div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    <span class="comment">#RELU-like activation</span></div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;    <span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(A.shape[1]):</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;        Y_prediction[0][i] = 1 <span class="keywordflow">if</span> A[0][i]&gt;0.5 <span class="keywordflow">else</span> 0</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    assert(Y_prediction.shape == (1, m))</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    <span class="keywordflow">return</span> Y_prediction</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a58e2fccbc2a5b25f8f30607629ed38ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58e2fccbc2a5b25f8f30607629ed38ae">&#9670;&nbsp;</a></span>propagate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.propagate </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement Forward, and Backward propagation, the cost function and its gradient . </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>weights, a numpy array of size (n,1) </td></tr>
    <tr><td class="paramname">b</td><td>bias, a scalar </td></tr>
    <tr><td class="paramname">X</td><td>data of size (n,m) </td></tr>
    <tr><td class="paramname">Y</td><td>true "label" vector {0,1} (1,m) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>cost negative log-likelihood cost for logistic regression </dd>
<dd>
dw gradient of the loss with respect to w, thus same shape as w </dd>
<dd>
db gradient of the loss with respect to b, thus same shape as b </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00129">129</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;<span class="keyword">def </span>propagate(w, b, X, Y):</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    m = X.shape[1]</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    z = linear(w, X, b)</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    h = sigmoid(z)</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    cost = deep_compute_cost(Y, h)</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    dw, db = derive_weight(X, Y, h)</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    assert(dw.shape == w.shape)</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    assert(db.dtype == float)</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    assert(cost.shape == ())</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    grads = {<span class="stringliteral">&quot;dw&quot;</span>: dw,</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;             <span class="stringliteral">&quot;db&quot;</span>: db}</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <span class="keywordflow">return</span> grads, cost</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a314bb57a2c296337ea2f273c46f4e7e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a314bb57a2c296337ea2f273c46f4e7e7">&#9670;&nbsp;</a></span>relu()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.relu </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>Z</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the RELU function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">Z</td><td>Output of the linear layer, of any shape </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A Post-activation parameter, of the same shape as Z </dd>
<dd>
cache a python dictionary containing "A" ; stored for computing the backward pass efficiently </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00200">200</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="keyword">def </span>relu(Z):</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    A = np.maximum(0,Z)</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    assert(A.shape == Z.shape)</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;    cache = Z </div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;    <span class="keywordflow">return</span> A, cache</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae93689ee55421e957e55192016219da0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae93689ee55421e957e55192016219da0">&#9670;&nbsp;</a></span>relu_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.relu_backward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the backward propagation for a single RELU unit. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dA</td><td>post-activation gradient, of any shape </td></tr>
    <tr><td class="paramname">cache</td><td>'Z' where we store for computing backward propagation efficiently </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>dZ Gradient of the cost with respect to Z </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00211">211</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;<span class="keyword">def </span>relu_backward(dA, cache):   </div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    Z = cache</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;    <span class="comment"># just converting dz to a correct object.</span></div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;    dZ = np.array(dA, copy=<span class="keyword">True</span>) </div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    <span class="comment"># When z &lt; 0, you should set dz to 0 as well. </span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;    dZ[Z &lt;= 0] = 0    </div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    <span class="keyword">assert</span> (dZ.shape == Z.shape)</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;    <span class="keywordflow">return</span> dZ</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="ab953b6a76b3d91de0f6b42d9d6d8b58b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab953b6a76b3d91de0f6b42d9d6d8b58b">&#9670;&nbsp;</a></span>sigmoid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.sigmoid </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>z</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>sigmoid activation </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">z</td><td>is the input (can be a scalar or an array) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>h the sigmoid of z </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00033">33</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="keyword">def </span>sigmoid(z):</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;    <span class="keywordflow">return</span> 1/(1+np.exp(-1*z))</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="aec2b9988afa351577eb52f731029fc89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec2b9988afa351577eb52f731029fc89">&#9670;&nbsp;</a></span>sigmoid_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.sigmoid_backward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dA</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implement the backward propagation for a single SIGMOID unit. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dA</td><td>post-activation gradient, of any shape </td></tr>
    <tr><td class="paramname">cache</td><td>'Z' where we store for computing backward propagation efficiently </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>dZ Gradient of the cost with respect to Z </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00225">225</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="keyword">def </span>sigmoid_backward(dA, cache):</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;    Z = cache    </div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;    s = 1/(1+np.exp(-Z))</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;    dZ = dA * s * (1-s)</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;    <span class="keyword">assert</span> (dZ.shape == Z.shape)</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;    <span class="keywordflow">return</span> dZ</div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="af4b8d65cdcdd5476f1fd2c871464c391"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4b8d65cdcdd5476f1fd2c871464c391">&#9670;&nbsp;</a></span>update_parameters()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.update_parameters </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parameters</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>learning_rate</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update parameters using gradient descent. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">parameters</td><td>python dictionary containing your parameters </td></tr>
    <tr><td class="paramname">grads</td><td>python dictionary containing your gradients, output of L_model_backward. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>updated parameters. </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00108">108</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="keyword">def </span>update_parameters(parameters, grads, learning_rate):</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;    L = len(parameters) // 2 </div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    <span class="comment"># Update rule for each parameter. Use a for loop.</span></div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;    <span class="keywordflow">for</span> l <span class="keywordflow">in</span> range(L):</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;        w=parameters[<span class="stringliteral">&quot;W&quot;</span> + str(l+1)]</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;        b=parameters[<span class="stringliteral">&quot;b&quot;</span> + str(l+1)]</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;        dw=learning_rate*grads[<span class="stringliteral">&#39;dW&#39;</span>+str(l+1)]</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        db=learning_rate*grads[<span class="stringliteral">&#39;db&#39;</span>+str(l+1)]</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        parameters[<span class="stringliteral">&quot;W&quot;</span> + str(l+1)], parameters[<span class="stringliteral">&quot;b&quot;</span> + str(l+1)]=\</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;            update_weight(w, dw, b, db, learning_rate)</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    <span class="keywordflow">return</span> parameters</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
<a id="a757ce3a23c10fbc489f586d772381d68"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a757ce3a23c10fbc489f586d772381d68">&#9670;&nbsp;</a></span>update_weight()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def aipy.aipy.utils.update_weight </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>db</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update weight values with single gradient descent step. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>(n,1) weight vector . </td></tr>
    <tr><td class="paramname">dw</td><td>(n,1) weight vector of dJ/dw. </td></tr>
    <tr><td class="paramname">b</td><td>scalar bias. </td></tr>
    <tr><td class="paramname">db</td><td>scalar dJ/db. </td></tr>
    <tr><td class="paramname">alpha</td><td>scalar is the learning reate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>tuple of new (w,b). </dd></dl>

<p class="definition">Definition at line <a class="el" href="utils_8py_source.html#l00098">98</a> of file <a class="el" href="utils_8py_source.html">utils.py</a>.</p>
<div class="fragment"><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;<span class="keyword">def </span>update_weight(w, dw, b, db, alpha):</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    w = w - alpha * dw</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    b = b - alpha * db</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    <span class="keywordflow">return</span> w, b</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160; </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
