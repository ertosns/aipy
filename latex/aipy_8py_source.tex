\hypertarget{aipy_8py_source}{}\doxysection{aipy.\+py}
\label{aipy_8py_source}\index{aipy/aipy.py@{aipy/aipy.py}}

\begin{DoxyCode}{0}
\DoxyCodeLine{00001 \textcolor{keyword}{from} utils \textcolor{keyword}{import} *}
\DoxyCodeLine{00002 }
\DoxyCodeLine{00003 }
\DoxyCodeLine{00006 }
\DoxyCodeLine{00007 }
\DoxyCodeLine{00008 }
\DoxyCodeLine{00014 \textcolor{keyword}{def }L\_model\_forward(X, parameters):}
\DoxyCodeLine{00015     caches = []}
\DoxyCodeLine{00016     A = X}
\DoxyCodeLine{00017     L = len(parameters) // 2}
\DoxyCodeLine{00018     \textcolor{keywordflow}{for} l \textcolor{keywordflow}{in} range(1, L):}
\DoxyCodeLine{00019         A\_prev = A }
\DoxyCodeLine{00020         parameters = deep\_initialization([2, len(A),])}
\DoxyCodeLine{00021         A, cache = deep\_linear\_activation\_forward(A\_prev, parameters[\textcolor{stringliteral}{'W'}], parameters[\textcolor{stringliteral}{'b'}], \textcolor{stringliteral}{'relu'})}
\DoxyCodeLine{00022     AL, cache = linear\_activation\_forward(A, parameters[\textcolor{stringliteral}{'W'}], parameters[\textcolor{stringliteral}{'b'}], \textcolor{stringliteral}{'sigmoid'})}
\DoxyCodeLine{00023     assert(AL.shape == (1,X.shape[1]))}
\DoxyCodeLine{00024     \textcolor{keywordflow}{return} AL, caches}
\DoxyCodeLine{00025 }
\DoxyCodeLine{00026 }
\DoxyCodeLine{00027 }
\DoxyCodeLine{00033 \textcolor{keyword}{def }L\_model\_backward(AL, Y, caches):}
\DoxyCodeLine{00034     grads = \{\}}
\DoxyCodeLine{00035     L = len(caches) \textcolor{comment}{\# the number of layers}}
\DoxyCodeLine{00036     m = AL.shape[1]}
\DoxyCodeLine{00037     \textcolor{comment}{\# after this line, Y is the same shape as AL}}
\DoxyCodeLine{00038     Y = Y.reshape(AL.shape) }
\DoxyCodeLine{00039     \textcolor{comment}{\# Initializing the backpropagation}}
\DoxyCodeLine{00040     dA\_prev = Y-\/AL}
\DoxyCodeLine{00041     dZL = sigmoid\_backward(dA\_prev, caches[\textcolor{stringliteral}{'Z'}+str(L)])}
\DoxyCodeLine{00042     \textcolor{comment}{\# Lth layer (SIGMOID -\/> LINEAR) gradients. Inputs: "dAL, current\_cache". Outputs: "grads["dAL-\/1"], grads["dWL"], grads["dbL"]}}
\DoxyCodeLine{00043     dWL = np.dot(caches[\textcolor{stringliteral}{'W'}+str(L)].T, dZL)}
\DoxyCodeLine{00044     dbL = dZL}
\DoxyCodeLine{00045     \textcolor{comment}{\#TODO (fix) review}}
\DoxyCodeLine{00046     linear\_cache=(AL, caches[\textcolor{stringliteral}{'W'}], caches[\textcolor{stringliteral}{'b'}])}
\DoxyCodeLine{00047     activation\_cache=caches}
\DoxyCodeLine{00048     current\_cache = (linear\_cache, activation\_cache)}
\DoxyCodeLine{00049     \textcolor{comment}{\#}}
\DoxyCodeLine{00050     grads[\textcolor{stringliteral}{"dA"} + str(L-\/1)] = dA\_prev}
\DoxyCodeLine{00051     grads[\textcolor{stringliteral}{"dW"} + str(L)] = dWL}
\DoxyCodeLine{00052     grads[\textcolor{stringliteral}{"db"} + str(L)] = dZ}
\DoxyCodeLine{00053     \textcolor{comment}{\# Loop from l=L-\/2 to l=0}}
\DoxyCodeLine{00054     \textcolor{keywordflow}{for} l \textcolor{keywordflow}{in} reversed(range(L-\/1)):}
\DoxyCodeLine{00055         \textcolor{comment}{\# lth layer: (RELU -\/> LINEAR) gradients.}}
\DoxyCodeLine{00056         \textcolor{comment}{\# Inputs: "grads["dA" + str(l + 1)], current\_cache". Outputs: "grads["dA" + str(l)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] }}
\DoxyCodeLine{00057         linear\_cache=(AL, caches[\textcolor{stringliteral}{'W'}], caches[\textcolor{stringliteral}{'b'}])}
\DoxyCodeLine{00058         activation\_cache=caches}
\DoxyCodeLine{00059         current\_cache = (linear\_cache, activation\_cache)}
\DoxyCodeLine{00060         dA\_prev\_temp, dW\_temp, db\_temp = deep\_linear\_activation\_backward(grads[\textcolor{stringliteral}{'dA'}+str(L-\/1)], current\_cache, \textcolor{stringliteral}{'relu'})}
\DoxyCodeLine{00061         grads[\textcolor{stringliteral}{"dA"} + str(l)] = dA\_prev\_temp}
\DoxyCodeLine{00062         grads[\textcolor{stringliteral}{"dW"} + str(l + 1)] = dW\_temp}
\DoxyCodeLine{00063         grads[\textcolor{stringliteral}{"db"} + str(l + 1)] = db\_temp}
\DoxyCodeLine{00064     \textcolor{keywordflow}{return} grads}

\end{DoxyCode}
